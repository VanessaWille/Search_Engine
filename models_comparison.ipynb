{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal is to compare different models\n",
    "\n",
    "For this task we already have a set of queries that have been evaluated, we will load them and use to calculate the scores for the models search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# trying to load the review bank\n",
    "try:\n",
    "    review_bank = pd.read_excel('reviews/review_bank.xlsx')\n",
    "except:\n",
    "    review_bank = pd.DataFrame()\n",
    "\n",
    "# the function for getting the ratings for pre-evaluated query-recipe pairs\n",
    "def lookup_rating(query, recipe):\n",
    "    try:\n",
    "        ratings = review_bank[(review_bank['Query'] == query) & (review_bank['Receita'] == recipe)][[\"Nota\", \"Evaluator\"]]\n",
    "        person_rating = ratings[ratings['Evaluator'] == \"Person\"]\n",
    "        if not person_rating.empty:\n",
    "            # If there is a human evaluation, it gets the preference\n",
    "            return person_rating.values[0][0]\n",
    "        else:\n",
    "            return ratings.iloc[0].values[0][0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the files in the output folder that are in the format Results_*.xlsx\n",
    "pattern = r\"Results_.*\\.xlsx$\"\n",
    "\n",
    "model_results_paths = [os.path.join('output', file) for file in os.listdir('output') if re.match(pattern, file)]\n",
    "\n",
    "models = {}\n",
    "for model_result_path in model_results_paths:\n",
    "    model_name = re.search(r\"Results_(.*).xlsx\", os.path.basename(model_result_path)).group(1)\n",
    "\n",
    "    result_df = pd.read_excel(model_result_path)\n",
    "    result_df[\"Nota\"] = result_df.apply(lambda row: lookup_rating(row['Query'], row['title']), axis=1)\n",
    "\n",
    "    models[model_name] = result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Bm25\n",
      "Avaliações ausentes: 0\n",
      "Média de pontuação: 2.6\n",
      "\n",
      "Modelo: hybrid\n",
      "Avaliações ausentes: 1\n",
      "Média de pontuação: 3.314814814814815\n",
      "\n",
      "Modelo: semantic\n",
      "Avaliações ausentes: 0\n",
      "Média de pontuação: 3.3454545454545452\n",
      "\n",
      "Modelo: Tfidf\n",
      "Avaliações ausentes: 0\n",
      "Média de pontuação: 2.6363636363636362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_reviews = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    df = models[model]\n",
    "    # Filtrar as linhas onde Nota é None\n",
    "    model_missing_reviews = df[df['Nota'].isnull()]\n",
    "    \n",
    "    # Calcular a média de Nota\n",
    "    mean_score = df['Nota'].mean()\n",
    "    \n",
    "    # Imprimir o relatório\n",
    "    print(f'Modelo: {model}')\n",
    "    print(f'Avaliações ausentes: {len(model_missing_reviews)}')\n",
    "    print(f'Média de pontuação: {mean_score}\\n')\n",
    "\n",
    "    missing_reviews = pd.concat([missing_reviews, model_missing_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Query</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>Nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Semantica</td>\n",
       "      <td>Pergunta difícil</td>\n",
       "      <td>what can I make for a romantic dinner</td>\n",
       "      <td>208724</td>\n",
       "      <td>pineapple tempeh</td>\n",
       "      <td>pineapple tempeh\\n\\nRecipe posted on: 2007-02-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tipo         Descrição                                  Query  \\\n",
       "52  Semantica  Pergunta difícil  what can I make for a romantic dinner   \n",
       "\n",
       "        id             title  \\\n",
       "52  208724  pineapple tempeh   \n",
       "\n",
       "                                                 body  Nota  \n",
       "52  pineapple tempeh\\n\\nRecipe posted on: 2007-02-...   NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
