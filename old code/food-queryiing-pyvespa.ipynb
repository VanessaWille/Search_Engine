{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db637322",
   "metadata": {},
   "source": [
    "## Create an application package\n",
    "\n",
    "The [application package](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.package.ApplicationPackage)\n",
    "has all the Vespa configuration files -\n",
    "create one from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5c2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field, Schema, Document, RankProfile, HNSW, RankProfile, Component, Parameter, FieldSet, GlobalPhaseRanking, Function\n",
    "\n",
    "package = ApplicationPackage(\n",
    "        name=\"findmypasta\",\n",
    "        schema=[Schema(\n",
    "            name=\"doc\",\n",
    "            document=Document(\n",
    "                fields=[\n",
    "                    Field(name=\"id\", type=\"string\", indexing=[\"summary\"]),\n",
    "                    Field(name=\"title\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"),\n",
    "                    Field(name=\"body\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\", bolding=True),\n",
    "                    Field(name=\"embedding\", type=\"tensor<float>(x[384])\",\n",
    "                        indexing=[\"input title . \\\" \\\" . input body\", \"embed\", \"index\", \"attribute\"],\n",
    "                        ann=HNSW(distance_metric=\"angular\"),\n",
    "                        is_document_field=False\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            fieldsets=[\n",
    "                FieldSet(name = \"default\", fields = [\"title\", \"body\"])\n",
    "            ],\n",
    "            rank_profiles=[\n",
    "                RankProfile(\n",
    "                    name=\"bm25\", \n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    functions=[Function(\n",
    "                        name=\"bm25sum\", expression=\"bm25(title) + bm25(body)\"\n",
    "                    )],\n",
    "                    first_phase=\"bm25sum\"\n",
    "                ),\n",
    "                RankProfile(\n",
    "                    name=\"semantic\", \n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    first_phase=\"closeness(field, embedding)\"\n",
    "                ),\n",
    "                RankProfile(\n",
    "                    name=\"fusion\", \n",
    "                    inherits=\"bm25\",\n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    first_phase=\"closeness(field, embedding)\",\n",
    "                    global_phase=GlobalPhaseRanking(\n",
    "                        expression=\"reciprocal_rank_fusion(bm25sum, closeness(field, embedding))\",\n",
    "                        rerank_count=1000\n",
    "                    )\n",
    "                )                \n",
    "            ]\n",
    "        )\n",
    "        ],\n",
    "        components=[Component(id=\"e5\", type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\"transformer-model\", {\"url\": \"https://github.com/vespa-engine/sample-apps/raw/master/simple-semantic-search/model/e5-small-v2-int8.onnx\"}),\n",
    "                Parameter(\"tokenizer-model\", {\"url\": \"https://raw.githubusercontent.com/vespa-engine/sample-apps/master/simple-semantic-search/model/tokenizer.json\"})\n",
    "            ]\n",
    "        )]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e2943",
   "metadata": {},
   "source": [
    "Note that the name cannot have `-` or `_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-savage",
   "metadata": {},
   "source": [
    "## Deploy the Vespa application \n",
    "\n",
    "Deploy `package` on the local machine using Docker,\n",
    "without leaving the notebook, by creating an instance of\n",
    "[VespaDocker](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.deployment.VespaDocker). `VespaDocker` connects\n",
    "to the local Docker daemon socket and starts the [Vespa docker image](https://hub.docker.com/r/vespaengine/vespa/). \n",
    "\n",
    "If this step fails, please check\n",
    "that the Docker daemon is running, and that the Docker daemon socket can be used by clients (Configurable under advanced settings in Docker Desktop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "canadian-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 30/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae2f91",
   "metadata": {},
   "source": [
    "`app` now holds a reference to a [Vespa](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa) instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-mustang",
   "metadata": {},
   "source": [
    "## Feeding documents to Vespa\n",
    "\n",
    "In this example we use the [HF Datasets](https://huggingface.co/docs/datasets/index) library to stream the\n",
    "[BeIR/nfcorpus](https://huggingface.co/datasets/BeIR/nfcorpus) dataset and index in our newly deployed Vespa instance. Read\n",
    "more about the [NFCorpus](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/):\n",
    "\n",
    ">NFCorpus is a full-text English retrieval data set for Medical Information Retrieval. \n",
    "\n",
    "The following uses the [stream](https://huggingface.co/docs/datasets/stream) option of datasets to stream the data without\n",
    "downloading all the contents locally. The `map` functionality allows us to convert the\n",
    "dataset fields into the expected feed format for `pyvespa` which expects a dict with the keys `id` and `fields`:\n",
    "\n",
    "` {Â \"id\": \"vespa-document-id\", \"fields\": {\"vespa_field\": \"vespa-field-value\"}} `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42fe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the csvs from the .archive folder, in a way that they are a dataset of the same format as the one used in the training of the model\n",
    "import pandas as pd\n",
    "\n",
    "types = {\n",
    "    \"contributor_id\": \"string\",\n",
    "    \"name\": \"string\",\n",
    "    \"id\": \"string\",\n",
    "    \"minutes\": \"int\",\n",
    "    \"tags\": \"string\",\n",
    "    \"nutrition\": \"string\",\n",
    "    \"n_steps\": \"int\",\n",
    "    \"n_ingredients\": \"int\",\n",
    "    \"steps\": \"string\",\n",
    "    \"description\": \"string\",\n",
    "    \"ingredients\": \"string\",\n",
    "    \"submitted\": \"string\"\n",
    "}\n",
    "df = pd.read_csv('archive/RAW_recipes.csv', dtype=types)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# creating a body field that is the concatenation of the fields\n",
    "df['body'] = df['name']\n",
    "df['body'] = df['body'] + ',\\nminutes to cook: ' + df['minutes'].astype(str) \n",
    "df['body'] = df['body'] + ', submitted in ' + df[\"submitted\"]\n",
    "df['body'] = df['body'] + \" by \" + df[\"contributor_id\"]\n",
    "df['body'] = df['body'] + \", \\n\" + df[\"tags\"]\n",
    "df['body'] = df['body'] + \" \\n \" + df['ingredients']\n",
    "df['body'] = df['body'] + '\\n' + df['steps']\n",
    "df['body'] = df['body'] + '\\n' + df['description']\n",
    "df['body'] = df['body'] + '\\n' + df['n_steps'].astype(str) + ' steps'\n",
    "df['body'] = df['body'] + '\\n' + df['n_ingredients'].astype(str) + ' ingredients'\n",
    "df['body'] = df['body'] + '\\n - nutrition: ' + df['nutrition']\n",
    "\n",
    "df['title'] = df['name']\n",
    "\n",
    "# creating a dataframe with the same format as the one used in the training of the model\n",
    "df = df[['id', 'title', 'body']]\n",
    "df = df.rename(columns={\"id\": \"id\", \"title\": \"title\", \"body\": \"body\"})\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# now converting to IterableDataset format that vespa expects\n",
    "def to_vespa_format(x):\n",
    "    return {\"id\": x[\"id\"], \"fields\": { \"title\": x[\"title\"], \"body\": x[\"body\"], \"id\": x[\"id\"]}}\n",
    "\n",
    "# creating the vespa_feed\n",
    "vespa_feed = df.apply(to_vespa_format, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6bc25",
   "metadata": {},
   "source": [
    "Now we can feed to Vespa using `feed_iterable` which accepts any `Iterable` and an optional callback function where we can\n",
    "check the outcome of each operation. The application is configured to use [embedding](https://docs.vespa.ai/en/embedding.html)\n",
    "functionality, that produce a vector embedding using a concatenation of the title and the body input fields. This step is computionally expensive. Read more\n",
    "about embedding inference in Vespa in the [Accelerating Transformer-based Embedding Retrieval with Vespa](https://blog.vespa.ai/accelerating-transformer-based-embedding-retrieval-with-vespa/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a261f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_feed_slice = vespa_feed[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96394afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress, VBox, Label, Layout  # Import Layout for styling\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def callback(response: VespaResponse, id: str):\n",
    "    if not response.is_successful():\n",
    "        print(f\"Error when feeding document {id}: {response.get_json()}\")\n",
    "    \n",
    "    # Update the progress bar value\n",
    "    progress_bar.value += 1\n",
    "    progress_label.value = f\"Feeding documents: {progress_bar.value}/{progress_bar.max} ({progress_bar.value * 100 / progress_bar.max:.2f}%)\"\n",
    "    update_estimated_time()\n",
    "\n",
    "def update_estimated_time():\n",
    "    if progress_bar.value > 0:\n",
    "        progress_bar.bar_style = 'info'\n",
    "        progress_bar.style.bar_color = '#00AA00'\n",
    "        progress_bar.style.description_width = 'initial'\n",
    "        remaining_documents = progress_bar.max - progress_bar.value\n",
    "        time_per_document = (time.time() - start_time) / progress_bar.value\n",
    "        estimated_remaining_time = remaining_documents * time_per_document\n",
    "        progress_bar.description = f'Progress: (ETA: {format_time(estimated_remaining_time)})'\n",
    "\n",
    "\n",
    "def format_time(time_in_seconds: float) -> str:\n",
    "    hours = int(time_in_seconds // 3600)\n",
    "    time_in_seconds = time_in_seconds - (hours * 3600)\n",
    "    minutes = int(time_in_seconds // 60)\n",
    "    seconds = int(time_in_seconds - (minutes * 60))\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "# Create a progress bar widget\n",
    "progress_bar = IntProgress(min=0, max=len(vespa_feed_slice), description='Progress:', layout=Layout(width='50%'))\n",
    "progress_label = Label(value=\"Feeding documents: 0/{}\".format(len(vespa_feed_slice)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7429132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5d55e0b66c429e96fdf0039cf79090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, description='Progress:', layout=Layout(width='50%'), max=400), Label(valueâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vespa.io import VespaResponse\n",
    "\n",
    "display(VBox([progress_bar, progress_label]))\n",
    "start_time = time.time()\n",
    "\n",
    "# Call the feeding function\n",
    "app.feed_iterable(vespa_feed_slice, schema=\"doc\", namespace=\"findmypasta\", callback=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-insertion",
   "metadata": {},
   "source": [
    "## Querying Vespa\n",
    "\n",
    "Using the [Vespa Query language](https://docs.vespa.ai/en/query-language.html) we can query the indexed data. \n",
    "\n",
    "- Using a context manager `with app.syncio() as session` to handle connection pooling ([best practices](https://cloud.vespa.ai/en/http-best-practices))\n",
    "- The query method accepts any valid Vespa [query api parameter](https://docs.vespa.ai/en/reference/query-api-reference.html) in `**kwargs`\n",
    "- Vespa api parameter names that contains `.` must be sent as `dict` parameters in the `body` method argument\n",
    "\n",
    "different retrieval and [ranking](https://docs.vespa.ai/en/ranking.html) strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20306d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def display_hits_as_df(response:VespaQueryResponse, fields) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for hit in response.hits:\n",
    "        record = {}\n",
    "        for field in fields:\n",
    "            record[field] = hit['fields'][field]\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798ec5c",
   "metadata": {},
   "source": [
    "### Plain Keyword search \n",
    "The following uses plain keyword search functionality with [bm25](https://docs.vespa.ai/en/reference/bm25.html) ranking, the `bm25` rank-profile was configured in the \n",
    "application package to use a linear combination of the bm25 score of the query terms against the title and the body field. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be392a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                              title\n",
      "0  474258     you want me to do what to the buttered noodles\n",
      "1  383339                    world s best  macaroni   cheese\n",
      "2  103009                                   30 minute dinner\n",
      "3  228627  a quartet of english and french cheese flavour...\n",
      "4  356359                   absolutely delicious pasta sauce\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"What is the best way to prepare pasta?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"bm25\"\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90b487e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                 title\n",
      "0  422277                     spaghetti squares\n",
      "1  100870            leftovers  spaghetti sauce\n",
      "2  121107           fooled ya   spaghetti sauce\n",
      "3   16356  amazing spaghetti with seafood sauce\n",
      "4  128830               t w a   spaghetti sauce\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How do I cook spaghetti?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"bm25\"\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d88472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                        title\n",
      "0  160696                   ally style pasta carbonara\n",
      "1   25400              alexander s spaghetti carbonara\n",
      "2  405737                           2 minute carbonara\n",
      "3  140173        15 minute shrimp carbonara fettuccine\n",
      "4  167435  amy s creamy jalapeo pimiento cheese spread\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"What's the carbonara recipe?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"bm25\"\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3932b3",
   "metadata": {},
   "source": [
    "### Plain Semantic Search \n",
    "The following uses dense vector representations of the query and the document and matching is performed and accelerated by Vespa's support for\n",
    "[approximate nearest neighbor search](https://docs.vespa.ai/en/approximate-nn-hnsw.html). \n",
    "The vector embedding representation of the text is obtained using Vespa's [embedder functionality](https://docs.vespa.ai/en/embedding.html#embedding-a-query-text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff6f0fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                       title\n",
      "0  339108       anne s nuts and bolts\n",
      "1  324047                 3  2  1 dip\n",
      "2  472363  amazingly perfect popovers\n",
      "3  114033              anne s tabouli\n",
      "4  232880                       amlou\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"Whats the best fast meal to a breakfest?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where ({targetHits:1000}nearestNeighbor(embedding,q)) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"semantic\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd25020",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "This is one approach to combine the two retrieval strategies and where we use Vespa's support for \n",
    "[cross-hits feature normalization and reciprocal rank fusion](https://docs.vespa.ai/en/phased-ranking.html#cross-hit-normalization-including-reciprocal-rank-fusion). This\n",
    "functionality is exposed in the context of `global` re-ranking, after the distributed query retrieval execution which might span 1000s of nodes. \n",
    "\n",
    "#### Hybrid search with the OR query operator\n",
    "\n",
    "This combines the two methods using logical disjunction (OR). Note that the first-phase expression in our `fusion` expression is only using the semantic score, this \n",
    "because usually semantic search provides better recall than sparse keyword search alone. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b5f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                            title\n",
      "0   14912                   5 star gourmet sauce for steak\n",
      "1  217201             i thought i had nothing to eat  rice\n",
      "2  400587  amazing cabbage  you ll want to eat a whole one\n",
      "3   59952                   global gourmet  taco casserole\n",
      "4  476655                      7 day soup diet  my version\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"I want to eat something gourmet, what do you suggest?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() or ({targetHits:1000}nearestNeighbor(embedding,q)) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa4eb0",
   "metadata": {},
   "source": [
    "#### Hybrid search with the RANK query operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9e77a",
   "metadata": {},
   "source": [
    "This combines the two methods using the [rank](https://docs.vespa.ai/en/reference/query-language-reference.html#rank) query operator. In this case\n",
    "we express that we want to retrieve the top-1000 documents using vector search, and then have sparse features like BM25 calculated as well (second operand \n",
    "of the rank operator). Finally the hits are re-ranked using the reciprocal rank fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb84a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                         title\n",
      "0  361646        alyssa s favorite fish\n",
      "1  454944      never fail  fish   chips\n",
      "2   35774   amazing tuna fish casserole\n",
      "3  495344               fish herb crust\n",
      "4  165856  chicken fried   fish fingers\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"Give me a recipe for a dinner with fish\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where rank({targetHits:1000}nearestNeighbor(embedding,q), userQuery()) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457aefc",
   "metadata": {},
   "source": [
    "#### Hybrid search with filters\n",
    "\n",
    "In this example we add another query term to the yql, restricting the nearest neighbor search to only consider documents that have vegetable in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b341042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                    title\n",
      "0  150851         almost vegetarian vegetable soup\n",
      "1  315721  angel hair pasta with garden vegetables\n",
      "2   71550           african spiced vegetable salad\n",
      "3  175922                 another vegetable paella\n",
      "4   31683                    3 vegetable casserole\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"I want to eat something with vegetables that is healthy and tasty\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where title contains \\\"vegetable\\\" and rank({targetHits:1000}nearestNeighbor(embedding,q), userQuery()) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28591491",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5064bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_docker.container.stop()\n",
    "vespa_docker.container.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1872b31",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This is just an intro into the capabilities of Vespa and pyvespa.\n",
    "Browse the site to learn more about schemas, feeding and queries - \n",
    "find more complex applications in\n",
    "[examples](https://pyvespa.readthedocs.io/en/latest/examples.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
